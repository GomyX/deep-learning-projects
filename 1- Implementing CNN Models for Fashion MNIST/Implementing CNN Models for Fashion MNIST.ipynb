{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing CNN Models for Fashion MNIST"
      ],
      "metadata": {
        "id": "bRYpHPpjmWZb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ok0-y1ejFnF"
      },
      "source": [
        "## some imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xRJkeh6KRpy",
        "outputId": "1977f9e8-60e5-4312-eba8-f09bea9b3936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting visualkeras\n",
            "  Downloading visualkeras-0.0.2-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mahmo\\anaconda3\\lib\\site-packages (from visualkeras) (9.2.0)\n",
            "Collecting aggdraw>=1.3.11\n",
            "  Downloading aggdraw-1.3.16-cp39-cp39-win_amd64.whl (43 kB)\n",
            "     -------------------------------------- 43.2/43.2 kB 263.7 kB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.18.1 in c:\\users\\mahmo\\anaconda3\\lib\\site-packages (from visualkeras) (1.21.5)\n",
            "Installing collected packages: aggdraw, visualkeras\n",
            "Successfully installed aggdraw-1.3.16 visualkeras-0.0.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_pSbECGfH2c"
      },
      "outputs": [],
      "source": [
        "##Importing modules\n",
        "import keras\n",
        "from keras.models import Sequential ,load_model , save_model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.optimizers import adam_v2 ,Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.layers import Conv2D, MaxPooling2D ,Conv3D\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.datasets import cifar10\n",
        "#  import pyplot and alias it as plt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import visualkeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5RCR3whjUDN"
      },
      "source": [
        "### data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfnmRWob__KD",
        "outputId": "3b021c2c-0a71-4888-aee6-2615e30ba287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(input_train, target_train), (input_test, target_test) = fashion_mnist.load_data()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5s5GqWioMbe",
        "outputId": "3cebd307-691e-463d-d7a7-339e4715de24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "y_train shape: (60000,)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "print('x_train shape:', input_train.shape)\n",
        "print('y_train shape:', target_train.shape)\n",
        "print(input_train.shape[0], 'train samples')\n",
        "print(input_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2uLh9ThSe_B",
        "outputId": "416ea356-229c-41f1-cb0e-f7ecfeb40e0c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UIMtsC2ABFc"
      },
      "outputs": [],
      "source": [
        "input_train =input_train/255\n",
        "input_test =input_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buC5WqJztoPE"
      },
      "outputs": [],
      "source": [
        "input_train=(input_train-np.mean(input_train))/np.std(input_train)\n",
        "input_test=(input_test-np.mean(input_test))/np.std(input_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc6Ry2VTAuY2"
      },
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "img_width, img_height = 28, 28\n",
        "batch_size = 128\n",
        "no_epochs = 100\n",
        "no_classes = 10\n",
        "random_state = 1234\n",
        "validation_split = 0.25\n",
        "verbosity = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr3czl8fQGKb",
        "outputId": "769047b3-19c9-489e-d73c-a2c36e8171b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1jjXmmWA0ZV"
      },
      "outputs": [],
      "source": [
        "# Reshape data\n",
        "input_train = input_train.reshape(input_train.shape[0], img_width, img_height, 1)\n",
        "input_test = input_test.reshape(input_test.shape[0], img_width, img_height, 1)\n",
        "input_shape = (img_width, img_height, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIwy-0FWSoJk",
        "outputId": "a127fac8-6431-40c1-c1f7-cb6ff207af68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7xvvice9rKR",
        "outputId": "794dc138-6148-44e6-f016-190e2a08f4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60000 (60000, 28, 28, 1) (10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Cast numbers to float32\n",
        "input_train = input_train.astype('float32')\n",
        "input_test = input_test.astype('float32')\n",
        "\n",
        "print(input_train.shape[0],input_train.shape,input_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IORVHxnbSNNo",
        "outputId": "8b959d3b-3085-4dd1-c334-7fbf04888b66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_test.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3DDkfqojdqM"
      },
      "source": [
        "### 1st model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH-wecOI9rMY",
        "outputId": "22d5c146-4a5e-4b22-f169-a3e2dd98831f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_19 (Conv2D)          (None, 28, 28, 64)        640       \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 14, 14, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               589952    \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 665,738\n",
            "Trainable params: 665,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape,strides=(1, 1),padding='same'))\n",
        " ##\"valid\" means no padding. \"same\" results in padding with zeros\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "# print the model architecture\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "Q8dcxazMxDcj",
        "outputId": "827f9873-9dea-4509-f604-dacbdc1625ca"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGBA size=622x150 at 0x7FD609C746A0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "visualkeras.layered_view(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlFGAEbXSzRU",
        "outputId": "f6c32c86-3128-4aea-ffb6-4a561e53073a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIhmjH7JVZSu"
      },
      "source": [
        "-  it took this model 9 mins to run on the gpu of colab\n",
        "-  and 32 mins to run on the cpu\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjwP3lkOS6U4",
        "outputId": "e39ab14b-e9cc-499f-df2d-157ed8f0115c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 9s 5ms/step - loss: 0.3939 - accuracy: 0.8587 - val_loss: 0.3083 - val_accuracy: 0.8863\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2532 - accuracy: 0.9085 - val_loss: 0.2649 - val_accuracy: 0.9057\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2042 - accuracy: 0.9245 - val_loss: 0.2397 - val_accuracy: 0.9133\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1702 - accuracy: 0.9373 - val_loss: 0.2302 - val_accuracy: 0.9197\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1387 - accuracy: 0.9488 - val_loss: 0.2495 - val_accuracy: 0.9159\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1125 - accuracy: 0.9586 - val_loss: 0.2534 - val_accuracy: 0.9187\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0931 - accuracy: 0.9654 - val_loss: 0.2672 - val_accuracy: 0.9209\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0744 - accuracy: 0.9722 - val_loss: 0.3238 - val_accuracy: 0.9076\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0653 - accuracy: 0.9764 - val_loss: 0.3270 - val_accuracy: 0.9208\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0531 - accuracy: 0.9803 - val_loss: 0.3332 - val_accuracy: 0.9162\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0458 - accuracy: 0.9830 - val_loss: 0.3834 - val_accuracy: 0.9141\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0409 - accuracy: 0.9851 - val_loss: 0.3978 - val_accuracy: 0.9187\n",
            "Epoch 13/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0408 - accuracy: 0.9845 - val_loss: 0.4026 - val_accuracy: 0.9189\n",
            "Epoch 14/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0319 - accuracy: 0.9882 - val_loss: 0.4674 - val_accuracy: 0.9163\n",
            "Epoch 15/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0292 - accuracy: 0.9895 - val_loss: 0.5052 - val_accuracy: 0.9143\n",
            "Epoch 16/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0316 - accuracy: 0.9891 - val_loss: 0.4967 - val_accuracy: 0.9189\n",
            "Epoch 17/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0283 - accuracy: 0.9895 - val_loss: 0.5078 - val_accuracy: 0.9166\n",
            "Epoch 18/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0251 - accuracy: 0.9911 - val_loss: 0.5135 - val_accuracy: 0.9174\n",
            "Epoch 19/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.4977 - val_accuracy: 0.9158\n",
            "Epoch 20/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0217 - accuracy: 0.9926 - val_loss: 0.6109 - val_accuracy: 0.9166\n",
            "Epoch 21/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0227 - accuracy: 0.9926 - val_loss: 0.5789 - val_accuracy: 0.9147\n",
            "Epoch 22/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0234 - accuracy: 0.9920 - val_loss: 0.5883 - val_accuracy: 0.9185\n",
            "Epoch 23/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.6236 - val_accuracy: 0.9179\n",
            "Epoch 24/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0245 - accuracy: 0.9919 - val_loss: 0.6212 - val_accuracy: 0.9182\n",
            "Epoch 25/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0179 - accuracy: 0.9936 - val_loss: 0.6253 - val_accuracy: 0.9187\n",
            "Epoch 26/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.6431 - val_accuracy: 0.9142\n",
            "Epoch 27/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.7190 - val_accuracy: 0.9191\n",
            "Epoch 28/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.6755 - val_accuracy: 0.9193\n",
            "Epoch 29/100\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.7159 - val_accuracy: 0.9137\n",
            "Epoch 30/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.7473 - val_accuracy: 0.9180\n",
            "Epoch 31/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0203 - accuracy: 0.9942 - val_loss: 0.7235 - val_accuracy: 0.9199\n",
            "Epoch 32/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0175 - accuracy: 0.9941 - val_loss: 0.8663 - val_accuracy: 0.9110\n",
            "Epoch 33/100\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.9369 - val_accuracy: 0.9082\n",
            "Epoch 34/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.8403 - val_accuracy: 0.9162\n",
            "Epoch 35/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0218 - accuracy: 0.9938 - val_loss: 0.8799 - val_accuracy: 0.9166\n",
            "Epoch 36/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0155 - accuracy: 0.9955 - val_loss: 0.8939 - val_accuracy: 0.9177\n",
            "Epoch 37/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.9541 - val_accuracy: 0.9169\n",
            "Epoch 38/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.7972 - val_accuracy: 0.9191\n",
            "Epoch 39/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0148 - accuracy: 0.9959 - val_loss: 0.8662 - val_accuracy: 0.9188\n",
            "Epoch 40/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0136 - accuracy: 0.9956 - val_loss: 0.9051 - val_accuracy: 0.9193\n",
            "Epoch 41/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0167 - accuracy: 0.9948 - val_loss: 0.9751 - val_accuracy: 0.9183\n",
            "Epoch 42/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 0.9903 - val_accuracy: 0.9149\n",
            "Epoch 43/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.9470 - val_accuracy: 0.9112\n",
            "Epoch 44/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0183 - accuracy: 0.9948 - val_loss: 1.0181 - val_accuracy: 0.9162\n",
            "Epoch 45/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0152 - accuracy: 0.9961 - val_loss: 1.0212 - val_accuracy: 0.9138\n",
            "Epoch 46/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0163 - accuracy: 0.9952 - val_loss: 0.9355 - val_accuracy: 0.9114\n",
            "Epoch 47/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0154 - accuracy: 0.9959 - val_loss: 0.9690 - val_accuracy: 0.9137\n",
            "Epoch 48/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0177 - accuracy: 0.9950 - val_loss: 0.9461 - val_accuracy: 0.9166\n",
            "Epoch 49/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 1.1335 - val_accuracy: 0.9169\n",
            "Epoch 50/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0173 - accuracy: 0.9955 - val_loss: 1.0179 - val_accuracy: 0.9155\n",
            "Epoch 51/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0164 - accuracy: 0.9952 - val_loss: 1.0161 - val_accuracy: 0.9167\n",
            "Epoch 52/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0128 - accuracy: 0.9965 - val_loss: 1.0310 - val_accuracy: 0.9127\n",
            "Epoch 53/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 1.0205 - val_accuracy: 0.9172\n",
            "Epoch 54/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 1.0594 - val_accuracy: 0.9134\n",
            "Epoch 55/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0150 - accuracy: 0.9962 - val_loss: 1.0622 - val_accuracy: 0.9211\n",
            "Epoch 56/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 1.0516 - val_accuracy: 0.9141\n",
            "Epoch 57/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0140 - accuracy: 0.9966 - val_loss: 1.0669 - val_accuracy: 0.9187\n",
            "Epoch 58/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0096 - accuracy: 0.9972 - val_loss: 1.1465 - val_accuracy: 0.9168\n",
            "Epoch 59/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0183 - accuracy: 0.9956 - val_loss: 1.2497 - val_accuracy: 0.9160\n",
            "Epoch 60/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0168 - accuracy: 0.9961 - val_loss: 1.1714 - val_accuracy: 0.9149\n",
            "Epoch 61/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0146 - accuracy: 0.9962 - val_loss: 1.1555 - val_accuracy: 0.9188\n",
            "Epoch 62/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0139 - accuracy: 0.9963 - val_loss: 1.2238 - val_accuracy: 0.9157\n",
            "Epoch 63/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0135 - accuracy: 0.9969 - val_loss: 1.1776 - val_accuracy: 0.9188\n",
            "Epoch 64/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 1.2748 - val_accuracy: 0.9172\n",
            "Epoch 65/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0142 - accuracy: 0.9962 - val_loss: 1.2573 - val_accuracy: 0.9187\n",
            "Epoch 66/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0163 - accuracy: 0.9965 - val_loss: 1.2066 - val_accuracy: 0.9164\n",
            "Epoch 67/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 1.3601 - val_accuracy: 0.9147\n",
            "Epoch 68/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0162 - accuracy: 0.9964 - val_loss: 1.3662 - val_accuracy: 0.9140\n",
            "Epoch 69/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0181 - accuracy: 0.9958 - val_loss: 1.2860 - val_accuracy: 0.9168\n",
            "Epoch 70/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0087 - accuracy: 0.9979 - val_loss: 1.3856 - val_accuracy: 0.9157\n",
            "Epoch 71/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 1.5420 - val_accuracy: 0.9118\n",
            "Epoch 72/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0195 - accuracy: 0.9958 - val_loss: 1.3791 - val_accuracy: 0.9162\n",
            "Epoch 73/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0120 - accuracy: 0.9971 - val_loss: 1.4466 - val_accuracy: 0.9216\n",
            "Epoch 74/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0153 - accuracy: 0.9970 - val_loss: 1.3938 - val_accuracy: 0.9151\n",
            "Epoch 75/100\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 1.4126 - val_accuracy: 0.9085\n",
            "Epoch 76/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0104 - accuracy: 0.9974 - val_loss: 1.5131 - val_accuracy: 0.9094\n",
            "Epoch 77/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 1.4215 - val_accuracy: 0.9155\n",
            "Epoch 78/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0089 - accuracy: 0.9977 - val_loss: 1.4814 - val_accuracy: 0.9182\n",
            "Epoch 79/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0147 - accuracy: 0.9966 - val_loss: 1.4572 - val_accuracy: 0.9162\n",
            "Epoch 80/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0117 - accuracy: 0.9972 - val_loss: 1.5286 - val_accuracy: 0.9123\n",
            "Epoch 81/100\n",
            "1500/1500 [==============================] - 10s 6ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 1.5874 - val_accuracy: 0.9156\n",
            "Epoch 82/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0134 - accuracy: 0.9970 - val_loss: 1.5836 - val_accuracy: 0.9154\n",
            "Epoch 83/100\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0145 - accuracy: 0.9964 - val_loss: 1.6004 - val_accuracy: 0.9178\n",
            "Epoch 84/100\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0142 - accuracy: 0.9971 - val_loss: 1.6252 - val_accuracy: 0.9203\n",
            "Epoch 85/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0095 - accuracy: 0.9979 - val_loss: 1.8488 - val_accuracy: 0.9138\n",
            "Epoch 86/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0181 - accuracy: 0.9966 - val_loss: 1.5969 - val_accuracy: 0.9157\n",
            "Epoch 87/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0103 - accuracy: 0.9975 - val_loss: 1.5540 - val_accuracy: 0.9143\n",
            "Epoch 88/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0189 - accuracy: 0.9965 - val_loss: 1.6924 - val_accuracy: 0.9169\n",
            "Epoch 89/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0128 - accuracy: 0.9974 - val_loss: 1.5854 - val_accuracy: 0.9160\n",
            "Epoch 90/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0128 - accuracy: 0.9971 - val_loss: 1.7265 - val_accuracy: 0.9133\n",
            "Epoch 91/100\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0194 - accuracy: 0.9961 - val_loss: 1.8112 - val_accuracy: 0.9148\n",
            "Epoch 92/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0088 - accuracy: 0.9982 - val_loss: 1.8130 - val_accuracy: 0.9149\n",
            "Epoch 93/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 1.7813 - val_accuracy: 0.9143\n",
            "Epoch 94/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 1.8021 - val_accuracy: 0.9150\n",
            "Epoch 95/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0169 - accuracy: 0.9966 - val_loss: 1.7837 - val_accuracy: 0.9142\n",
            "Epoch 96/100\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0182 - accuracy: 0.9966 - val_loss: 1.6497 - val_accuracy: 0.9149\n",
            "Epoch 97/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0080 - accuracy: 0.9980 - val_loss: 1.5917 - val_accuracy: 0.9200\n",
            "Epoch 98/100\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0172 - accuracy: 0.9968 - val_loss: 1.6930 - val_accuracy: 0.9128\n",
            "Epoch 99/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0158 - accuracy: 0.9970 - val_loss: 1.8911 - val_accuracy: 0.9130\n",
            "Epoch 100/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0097 - accuracy: 0.9978 - val_loss: 1.6789 - val_accuracy: 0.9161\n"
          ]
        }
      ],
      "source": [
        "# Fit data to model\n",
        "history=model.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSPnCEoMG8EU",
        "outputId": "937a9796-d680-495f-aeee-c19d8607eb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 1.7138195037841797 / Test accuracy: 0.9165999889373779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Generate generalization metrics\n",
        "score = model.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# # Save the model\n",
        "filepath = './saved_model'\n",
        "save_model(model, filepath)\n",
        "\n",
        "# Load the model\n",
        "model = load_model(filepath, compile = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYBC4e5OjmpS"
      },
      "source": [
        "### 2nd model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUzlSYSRj6-x",
        "outputId": "fde39379-0b8f-4b78-e061-cb383094711b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 128)       1280      \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 13, 13, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 13, 13, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 5, 5, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 5, 5, 256)         0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,610,506\n",
            "Trainable params: 1,610,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model_128 = Sequential()\n",
        "model_128.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=input_shape,strides=(1, 1),padding=\"valid\"))\n",
        "# mode12864alid\" means no padding. \"same\" results in padding with zeros\n",
        "model_128.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_128.add(Dropout(0.25))\n",
        "model_128.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model_128.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_128.add(Dropout(0.25))\n",
        "model_128.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model_128.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_128.add(Dropout(0.25))\n",
        "model_128.add(Flatten())\n",
        "model_128.add(Dense(256, activation='relu'))\n",
        "model_128.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_128.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "# print the model architecture\n",
        "model_128.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2AF6FJ5kTHD",
        "outputId": "d5c4eaea-ced1-4aa0-8de9-339b3286b3d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 8s 18ms/step - loss: 0.6143 - accuracy: 0.7724 - val_loss: 0.4127 - val_accuracy: 0.8483\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3987 - accuracy: 0.8537 - val_loss: 0.3591 - val_accuracy: 0.8694\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3427 - accuracy: 0.8755 - val_loss: 0.3421 - val_accuracy: 0.8727\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.3087 - accuracy: 0.8855 - val_loss: 0.3119 - val_accuracy: 0.8884\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.2805 - accuracy: 0.8965 - val_loss: 0.2897 - val_accuracy: 0.8928\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.2693 - accuracy: 0.9006 - val_loss: 0.2802 - val_accuracy: 0.8978\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.2501 - accuracy: 0.9074 - val_loss: 0.2797 - val_accuracy: 0.9012\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.2376 - accuracy: 0.9124 - val_loss: 0.2640 - val_accuracy: 0.9042\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.2234 - accuracy: 0.9154 - val_loss: 0.2712 - val_accuracy: 0.9035\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.2103 - accuracy: 0.9218 - val_loss: 0.2757 - val_accuracy: 0.9003\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.2016 - accuracy: 0.9230 - val_loss: 0.2995 - val_accuracy: 0.9004\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1910 - accuracy: 0.9282 - val_loss: 0.2813 - val_accuracy: 0.9007\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1820 - accuracy: 0.9319 - val_loss: 0.2640 - val_accuracy: 0.9088\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.1731 - accuracy: 0.9345 - val_loss: 0.2764 - val_accuracy: 0.9063\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.1685 - accuracy: 0.9361 - val_loss: 0.2796 - val_accuracy: 0.9046\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.1578 - accuracy: 0.9407 - val_loss: 0.2801 - val_accuracy: 0.9067\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.1520 - accuracy: 0.9424 - val_loss: 0.2909 - val_accuracy: 0.9007\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.1468 - accuracy: 0.9438 - val_loss: 0.2858 - val_accuracy: 0.9015\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1428 - accuracy: 0.9449 - val_loss: 0.2899 - val_accuracy: 0.9064\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1389 - accuracy: 0.9471 - val_loss: 0.2840 - val_accuracy: 0.9094\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.1310 - accuracy: 0.9497 - val_loss: 0.3170 - val_accuracy: 0.9038\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1269 - accuracy: 0.9510 - val_loss: 0.3033 - val_accuracy: 0.9073\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1229 - accuracy: 0.9549 - val_loss: 0.3014 - val_accuracy: 0.9071\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1227 - accuracy: 0.9534 - val_loss: 0.3400 - val_accuracy: 0.9007\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1190 - accuracy: 0.9546 - val_loss: 0.3151 - val_accuracy: 0.9058\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1158 - accuracy: 0.9564 - val_loss: 0.3332 - val_accuracy: 0.9013\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.1121 - accuracy: 0.9567 - val_loss: 0.3141 - val_accuracy: 0.9078\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.1117 - accuracy: 0.9581 - val_loss: 0.3172 - val_accuracy: 0.9035\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1072 - accuracy: 0.9597 - val_loss: 0.3335 - val_accuracy: 0.9058\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1073 - accuracy: 0.9597 - val_loss: 0.3252 - val_accuracy: 0.9105\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.1011 - accuracy: 0.9620 - val_loss: 0.3284 - val_accuracy: 0.9086\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.1012 - accuracy: 0.9614 - val_loss: 0.3291 - val_accuracy: 0.9092\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0944 - accuracy: 0.9633 - val_loss: 0.3402 - val_accuracy: 0.9066\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0977 - accuracy: 0.9633 - val_loss: 0.3452 - val_accuracy: 0.9026\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0952 - accuracy: 0.9646 - val_loss: 0.3404 - val_accuracy: 0.9093\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0942 - accuracy: 0.9648 - val_loss: 0.3335 - val_accuracy: 0.9057\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0904 - accuracy: 0.9668 - val_loss: 0.3420 - val_accuracy: 0.9024\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0895 - accuracy: 0.9661 - val_loss: 0.3356 - val_accuracy: 0.9053\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0870 - accuracy: 0.9683 - val_loss: 0.3567 - val_accuracy: 0.9061\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0882 - accuracy: 0.9676 - val_loss: 0.3659 - val_accuracy: 0.9047\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0825 - accuracy: 0.9697 - val_loss: 0.3729 - val_accuracy: 0.9068\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0861 - accuracy: 0.9688 - val_loss: 0.3603 - val_accuracy: 0.9055\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0821 - accuracy: 0.9691 - val_loss: 0.3513 - val_accuracy: 0.9069\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0815 - accuracy: 0.9701 - val_loss: 0.3646 - val_accuracy: 0.9056\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0785 - accuracy: 0.9702 - val_loss: 0.3783 - val_accuracy: 0.9068\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0783 - accuracy: 0.9708 - val_loss: 0.3607 - val_accuracy: 0.9084\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0774 - accuracy: 0.9714 - val_loss: 0.3957 - val_accuracy: 0.9056\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0782 - accuracy: 0.9702 - val_loss: 0.4010 - val_accuracy: 0.9043\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0751 - accuracy: 0.9728 - val_loss: 0.3823 - val_accuracy: 0.9065\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0738 - accuracy: 0.9732 - val_loss: 0.3600 - val_accuracy: 0.9115\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0712 - accuracy: 0.9750 - val_loss: 0.4042 - val_accuracy: 0.9052\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.0762 - accuracy: 0.9719 - val_loss: 0.3744 - val_accuracy: 0.9053\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0712 - accuracy: 0.9735 - val_loss: 0.3710 - val_accuracy: 0.9039\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0721 - accuracy: 0.9740 - val_loss: 0.4063 - val_accuracy: 0.9068\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.0672 - accuracy: 0.9755 - val_loss: 0.4218 - val_accuracy: 0.9051\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0685 - accuracy: 0.9753 - val_loss: 0.3825 - val_accuracy: 0.9058\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0721 - accuracy: 0.9734 - val_loss: 0.3825 - val_accuracy: 0.9090\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0720 - accuracy: 0.9739 - val_loss: 0.3944 - val_accuracy: 0.9084\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 0.3901 - val_accuracy: 0.9078\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0704 - accuracy: 0.9744 - val_loss: 0.3801 - val_accuracy: 0.9065\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0644 - accuracy: 0.9768 - val_loss: 0.3751 - val_accuracy: 0.9110\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0634 - accuracy: 0.9770 - val_loss: 0.3929 - val_accuracy: 0.9081\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0626 - accuracy: 0.9773 - val_loss: 0.4016 - val_accuracy: 0.9087\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0645 - accuracy: 0.9771 - val_loss: 0.3793 - val_accuracy: 0.9077\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0672 - accuracy: 0.9759 - val_loss: 0.3691 - val_accuracy: 0.9072\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0641 - accuracy: 0.9765 - val_loss: 0.4066 - val_accuracy: 0.9062\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0609 - accuracy: 0.9781 - val_loss: 0.4126 - val_accuracy: 0.9076\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0594 - accuracy: 0.9787 - val_loss: 0.3862 - val_accuracy: 0.9097\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0614 - accuracy: 0.9774 - val_loss: 0.3915 - val_accuracy: 0.9093\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0594 - accuracy: 0.9791 - val_loss: 0.3804 - val_accuracy: 0.9067\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.4019 - val_accuracy: 0.9076\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0596 - accuracy: 0.9797 - val_loss: 0.4143 - val_accuracy: 0.9051\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0582 - accuracy: 0.9793 - val_loss: 0.4182 - val_accuracy: 0.9067\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0578 - accuracy: 0.9796 - val_loss: 0.4393 - val_accuracy: 0.9076\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0614 - accuracy: 0.9792 - val_loss: 0.4286 - val_accuracy: 0.9093\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.0634 - accuracy: 0.9773 - val_loss: 0.4018 - val_accuracy: 0.9027\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0543 - accuracy: 0.9799 - val_loss: 0.4222 - val_accuracy: 0.9098\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0575 - accuracy: 0.9794 - val_loss: 0.4014 - val_accuracy: 0.9066\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0553 - accuracy: 0.9805 - val_loss: 0.4014 - val_accuracy: 0.9043\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.4080 - val_accuracy: 0.9060\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0613 - accuracy: 0.9786 - val_loss: 0.4241 - val_accuracy: 0.9051\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 7s 17ms/step - loss: 0.0554 - accuracy: 0.9806 - val_loss: 0.4291 - val_accuracy: 0.9053\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0548 - accuracy: 0.9806 - val_loss: 0.4338 - val_accuracy: 0.9068\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.4268 - val_accuracy: 0.9040\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0535 - accuracy: 0.9814 - val_loss: 0.4197 - val_accuracy: 0.9078\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.4109 - val_accuracy: 0.9076\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0506 - accuracy: 0.9825 - val_loss: 0.4135 - val_accuracy: 0.9093\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0543 - accuracy: 0.9811 - val_loss: 0.4252 - val_accuracy: 0.9062\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0530 - accuracy: 0.9816 - val_loss: 0.4360 - val_accuracy: 0.9091\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0538 - accuracy: 0.9815 - val_loss: 0.4331 - val_accuracy: 0.9078\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0506 - accuracy: 0.9829 - val_loss: 0.4352 - val_accuracy: 0.9083\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0496 - accuracy: 0.9826 - val_loss: 0.4243 - val_accuracy: 0.9088\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 0.4076 - val_accuracy: 0.9079\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 7s 18ms/step - loss: 0.0497 - accuracy: 0.9825 - val_loss: 0.4409 - val_accuracy: 0.9084\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 6s 16ms/step - loss: 0.0474 - accuracy: 0.9832 - val_loss: 0.4111 - val_accuracy: 0.9087\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 0.4236 - val_accuracy: 0.9086\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0461 - accuracy: 0.9841 - val_loss: 0.4471 - val_accuracy: 0.9074\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0518 - accuracy: 0.9817 - val_loss: 0.4368 - val_accuracy: 0.9073\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0507 - accuracy: 0.9825 - val_loss: 0.4216 - val_accuracy: 0.9071\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 6s 17ms/step - loss: 0.0517 - accuracy: 0.9823 - val_loss: 0.4487 - val_accuracy: 0.9115\n",
            "Test loss: 0.48222875595092773 / Test accuracy: 0.9075000286102295\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Fit data to model\n",
        "history=model_128.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)\n",
        "\n",
        "# Generate generalization metrics\n",
        "score = model_128.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# # Save the model\n",
        "filepath = './saved_model'\n",
        "save_model(model_128, filepath)\n",
        "\n",
        "# Load the model\n",
        "model_64 = load_model(filepath, compile = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHh6EdlzqgsY"
      },
      "source": [
        "### model 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pci67aRkqgWU",
        "outputId": "710e58d9-3f83-4c4d-e8d4-cab1954fa494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 26, 26, 256)       2560      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 13, 13, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 13, 13, 256)       0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 11, 11, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 5, 5, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 5, 5, 512)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 3, 3, 1024)        4719616   \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 1, 1, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 1, 1, 1024)        0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,167,306\n",
            "Trainable params: 6,167,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model_256 = Sequential()\n",
        "model_256.add(Conv2D(256, kernel_size=(3, 3), activation='relu', input_shape=input_shape,strides=(1, 1),padding=\"valid\"))\n",
        "# mode25664alid\" means no padding. \"same\" results in padding with zeros\n",
        "model_256.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_256.add(Dropout(0.25))\n",
        "model_256.add(Conv2D(512, kernel_size=(3, 3), activation='relu'))\n",
        "model_256.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_256.add(Dropout(0.25))\n",
        "model_256.add(Conv2D(1024, kernel_size=(3, 3), activation='relu'))\n",
        "model_256.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model_256.add(Dropout(0.25))\n",
        "model_256.add(Flatten())\n",
        "model_256.add(Dense(256, activation='relu'))\n",
        "model_256.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_256.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "# print the model architecture\n",
        "model_256.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-a5zm720q8Go",
        "outputId": "42a208dc-b4c7-421b-c49b-882147652e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 18s 42ms/step - loss: 0.5537 - accuracy: 0.7954 - val_loss: 0.3817 - val_accuracy: 0.8601\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 16s 41ms/step - loss: 0.3704 - accuracy: 0.8639 - val_loss: 0.3795 - val_accuracy: 0.8556\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.3197 - accuracy: 0.8809 - val_loss: 0.3129 - val_accuracy: 0.8855\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.2893 - accuracy: 0.8928 - val_loss: 0.2970 - val_accuracy: 0.8896\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.2614 - accuracy: 0.9013 - val_loss: 0.2788 - val_accuracy: 0.8970\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.2400 - accuracy: 0.9098 - val_loss: 0.2802 - val_accuracy: 0.8986\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.2208 - accuracy: 0.9171 - val_loss: 0.2927 - val_accuracy: 0.8924\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.2030 - accuracy: 0.9230 - val_loss: 0.2816 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1870 - accuracy: 0.9279 - val_loss: 0.2751 - val_accuracy: 0.9047\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.1788 - accuracy: 0.9324 - val_loss: 0.2710 - val_accuracy: 0.9062\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1700 - accuracy: 0.9347 - val_loss: 0.2899 - val_accuracy: 0.8982\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1577 - accuracy: 0.9406 - val_loss: 0.2820 - val_accuracy: 0.9031\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.1480 - accuracy: 0.9440 - val_loss: 0.2925 - val_accuracy: 0.9039\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1347 - accuracy: 0.9477 - val_loss: 0.3075 - val_accuracy: 0.9022\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1285 - accuracy: 0.9514 - val_loss: 0.2995 - val_accuracy: 0.9026\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1243 - accuracy: 0.9537 - val_loss: 0.3274 - val_accuracy: 0.8999\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1177 - accuracy: 0.9552 - val_loss: 0.3130 - val_accuracy: 0.9065\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.1130 - accuracy: 0.9565 - val_loss: 0.3139 - val_accuracy: 0.9039\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.1042 - accuracy: 0.9606 - val_loss: 0.3447 - val_accuracy: 0.9020\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0975 - accuracy: 0.9633 - val_loss: 0.3389 - val_accuracy: 0.9051\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0943 - accuracy: 0.9648 - val_loss: 0.3610 - val_accuracy: 0.9036\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 16s 43ms/step - loss: 0.0964 - accuracy: 0.9644 - val_loss: 0.3431 - val_accuracy: 0.9073\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0884 - accuracy: 0.9673 - val_loss: 0.3271 - val_accuracy: 0.9038\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0836 - accuracy: 0.9693 - val_loss: 0.3221 - val_accuracy: 0.9080\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0818 - accuracy: 0.9686 - val_loss: 0.3560 - val_accuracy: 0.9097\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 16s 43ms/step - loss: 0.0790 - accuracy: 0.9703 - val_loss: 0.3646 - val_accuracy: 0.9090\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0759 - accuracy: 0.9720 - val_loss: 0.3793 - val_accuracy: 0.9088\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0780 - accuracy: 0.9717 - val_loss: 0.3585 - val_accuracy: 0.9081\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0744 - accuracy: 0.9724 - val_loss: 0.3641 - val_accuracy: 0.9085\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0718 - accuracy: 0.9736 - val_loss: 0.3711 - val_accuracy: 0.9069\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0695 - accuracy: 0.9752 - val_loss: 0.4318 - val_accuracy: 0.9024\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0703 - accuracy: 0.9741 - val_loss: 0.4378 - val_accuracy: 0.9028\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0708 - accuracy: 0.9742 - val_loss: 0.4001 - val_accuracy: 0.9068\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0655 - accuracy: 0.9760 - val_loss: 0.4290 - val_accuracy: 0.9078\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0655 - accuracy: 0.9759 - val_loss: 0.3921 - val_accuracy: 0.9068\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0560 - accuracy: 0.9796 - val_loss: 0.4230 - val_accuracy: 0.9107\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0618 - accuracy: 0.9778 - val_loss: 0.3985 - val_accuracy: 0.9096\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0613 - accuracy: 0.9784 - val_loss: 0.4348 - val_accuracy: 0.9081\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0574 - accuracy: 0.9797 - val_loss: 0.4151 - val_accuracy: 0.9107\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0534 - accuracy: 0.9806 - val_loss: 0.4616 - val_accuracy: 0.9050\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0566 - accuracy: 0.9792 - val_loss: 0.4475 - val_accuracy: 0.9056\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0566 - accuracy: 0.9801 - val_loss: 0.4491 - val_accuracy: 0.9050\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0533 - accuracy: 0.9815 - val_loss: 0.4551 - val_accuracy: 0.9072\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0513 - accuracy: 0.9822 - val_loss: 0.4617 - val_accuracy: 0.9080\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0544 - accuracy: 0.9801 - val_loss: 0.4576 - val_accuracy: 0.9062\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0545 - accuracy: 0.9812 - val_loss: 0.4589 - val_accuracy: 0.9088\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0500 - accuracy: 0.9835 - val_loss: 0.4577 - val_accuracy: 0.9057\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0491 - accuracy: 0.9832 - val_loss: 0.4427 - val_accuracy: 0.9061\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0505 - accuracy: 0.9817 - val_loss: 0.4889 - val_accuracy: 0.9081\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0520 - accuracy: 0.9814 - val_loss: 0.4291 - val_accuracy: 0.9089\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0490 - accuracy: 0.9824 - val_loss: 0.4431 - val_accuracy: 0.9069\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0404 - accuracy: 0.9861 - val_loss: 0.4607 - val_accuracy: 0.9087\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0442 - accuracy: 0.9843 - val_loss: 0.4770 - val_accuracy: 0.9030\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0493 - accuracy: 0.9829 - val_loss: 0.4927 - val_accuracy: 0.9040\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0481 - accuracy: 0.9830 - val_loss: 0.4693 - val_accuracy: 0.9024\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0442 - accuracy: 0.9845 - val_loss: 0.4976 - val_accuracy: 0.9063\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0441 - accuracy: 0.9845 - val_loss: 0.4625 - val_accuracy: 0.9068\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0446 - accuracy: 0.9845 - val_loss: 0.5161 - val_accuracy: 0.9045\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0452 - accuracy: 0.9840 - val_loss: 0.4839 - val_accuracy: 0.9037\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0434 - accuracy: 0.9849 - val_loss: 0.4421 - val_accuracy: 0.9047\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 0.4820 - val_accuracy: 0.9069\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0401 - accuracy: 0.9859 - val_loss: 0.4851 - val_accuracy: 0.9009\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0442 - accuracy: 0.9846 - val_loss: 0.4825 - val_accuracy: 0.9028\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0426 - accuracy: 0.9852 - val_loss: 0.4962 - val_accuracy: 0.9070\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0425 - accuracy: 0.9856 - val_loss: 0.4928 - val_accuracy: 0.9062\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0390 - accuracy: 0.9867 - val_loss: 0.5203 - val_accuracy: 0.9060\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.5059 - val_accuracy: 0.9087\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0388 - accuracy: 0.9873 - val_loss: 0.5098 - val_accuracy: 0.9067\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0417 - accuracy: 0.9859 - val_loss: 0.5049 - val_accuracy: 0.9054\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0373 - accuracy: 0.9878 - val_loss: 0.5147 - val_accuracy: 0.9065\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0348 - accuracy: 0.9886 - val_loss: 0.5306 - val_accuracy: 0.9077\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0364 - accuracy: 0.9879 - val_loss: 0.5628 - val_accuracy: 0.9028\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0415 - accuracy: 0.9859 - val_loss: 0.5294 - val_accuracy: 0.9072\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0405 - accuracy: 0.9869 - val_loss: 0.5087 - val_accuracy: 0.9036\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0385 - accuracy: 0.9868 - val_loss: 0.5049 - val_accuracy: 0.9077\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0362 - accuracy: 0.9878 - val_loss: 0.5214 - val_accuracy: 0.9055\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.5586 - val_accuracy: 0.9063\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0392 - accuracy: 0.9868 - val_loss: 0.5043 - val_accuracy: 0.9093\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.5370 - val_accuracy: 0.9104\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0341 - accuracy: 0.9887 - val_loss: 0.5421 - val_accuracy: 0.9050\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0371 - accuracy: 0.9879 - val_loss: 0.5387 - val_accuracy: 0.9028\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0389 - accuracy: 0.9872 - val_loss: 0.5357 - val_accuracy: 0.9070\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0320 - accuracy: 0.9894 - val_loss: 0.5341 - val_accuracy: 0.9061\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.5329 - val_accuracy: 0.9078\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.5283 - val_accuracy: 0.9098\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0354 - accuracy: 0.9878 - val_loss: 0.5375 - val_accuracy: 0.9072\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0337 - accuracy: 0.9887 - val_loss: 0.5680 - val_accuracy: 0.9052\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0372 - accuracy: 0.9876 - val_loss: 0.5408 - val_accuracy: 0.9039\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0350 - accuracy: 0.9887 - val_loss: 0.5270 - val_accuracy: 0.9043\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0389 - accuracy: 0.9877 - val_loss: 0.5547 - val_accuracy: 0.9037\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0340 - accuracy: 0.9890 - val_loss: 0.5587 - val_accuracy: 0.9047\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0330 - accuracy: 0.9888 - val_loss: 0.5583 - val_accuracy: 0.9052\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.5605 - val_accuracy: 0.9037\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0297 - accuracy: 0.9904 - val_loss: 0.5750 - val_accuracy: 0.9032\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0327 - accuracy: 0.9896 - val_loss: 0.5809 - val_accuracy: 0.9058\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 16s 42ms/step - loss: 0.0297 - accuracy: 0.9906 - val_loss: 0.6158 - val_accuracy: 0.9021\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0359 - accuracy: 0.9889 - val_loss: 0.5782 - val_accuracy: 0.9077\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.6005 - val_accuracy: 0.9041\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 0.5955 - val_accuracy: 0.9076\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 15s 41ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.5866 - val_accuracy: 0.9077\n",
            "Test loss: 0.6295825242996216 / Test accuracy: 0.9054999947547913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Fit data to model\n",
        "history=model_256.fit(input_train, target_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=no_epochs,\n",
        "          verbose=verbosity,\n",
        "          validation_split=validation_split)\n",
        "\n",
        "# Generate generalization metrics\n",
        "score = model_256.evaluate(input_test, target_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# # Save the model\n",
        "filepath = './saved_model'\n",
        "save_model(model_256, filepath)\n",
        "\n",
        "# Load the model\n",
        "model_256 = load_model(filepath, compile = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp60hvdGuSqG"
      },
      "source": [
        "### testing on Cifar10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyK9lifFuSNI",
        "outputId": "d51872f0-b873-4fa1-a48a-ea0e15511520"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 503s 3us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL_DkDWMCp2V"
      },
      "outputs": [],
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 100\n",
        "data_augmentation = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddi9FOZXXwWs",
        "outputId": "cc45f728-458a-4b82-8ff4-5e98d6e04bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               802944    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 879,882\n",
            "Trainable params: 879,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=x_train.shape[1:],strides=(1, 1),padding='same'))\n",
        " ##\"valid\" means no padding. \"same\" results in padding with zeros\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=sparse_categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "# print the model architecture\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LupoEXI5wQyJ"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jZeKIG_mwmO7"
      },
      "outputs": [],
      "source": [
        "#one hot encoding\n",
        "y_train =np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxxh-GlfBEK3"
      },
      "outputs": [],
      "source": [
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiivLZmjALE-",
        "outputId": "4a762d00-fc55-4e21-fc5f-f07e137507f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1250/1250 [==============================] - 80s 63ms/step - loss: 1.7111 - accuracy: 0.3924 - val_loss: 1.4669 - val_accuracy: 0.4851\n",
            "Epoch 2/100\n",
            "1250/1250 [==============================] - 107s 86ms/step - loss: 1.3722 - accuracy: 0.5153 - val_loss: 1.2841 - val_accuracy: 0.5552\n",
            "Epoch 3/100\n",
            "1250/1250 [==============================] - 90s 72ms/step - loss: 1.2297 - accuracy: 0.5688 - val_loss: 1.2397 - val_accuracy: 0.5582\n",
            "Epoch 4/100\n",
            "1250/1250 [==============================] - 88s 71ms/step - loss: 1.1392 - accuracy: 0.6007 - val_loss: 1.1544 - val_accuracy: 0.5996\n",
            "Epoch 5/100\n",
            "1250/1250 [==============================] - 86s 68ms/step - loss: 1.0677 - accuracy: 0.6277 - val_loss: 1.0788 - val_accuracy: 0.6266\n",
            "Epoch 6/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 1.0090 - accuracy: 0.6500 - val_loss: 1.0465 - val_accuracy: 0.6415\n",
            "Epoch 7/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.9626 - accuracy: 0.6668 - val_loss: 1.0100 - val_accuracy: 0.6527\n",
            "Epoch 8/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.9200 - accuracy: 0.6812 - val_loss: 0.9787 - val_accuracy: 0.6638\n",
            "Epoch 9/100\n",
            "1250/1250 [==============================] - 86s 69ms/step - loss: 0.8815 - accuracy: 0.6963 - val_loss: 0.9561 - val_accuracy: 0.6750\n",
            "Epoch 10/100\n",
            "1250/1250 [==============================] - 85s 68ms/step - loss: 0.8477 - accuracy: 0.7086 - val_loss: 0.9284 - val_accuracy: 0.6814\n",
            "Epoch 11/100\n",
            "1250/1250 [==============================] - 92s 74ms/step - loss: 0.8117 - accuracy: 0.7214 - val_loss: 0.9134 - val_accuracy: 0.6874\n",
            "Epoch 12/100\n",
            "1250/1250 [==============================] - 96s 77ms/step - loss: 0.7833 - accuracy: 0.7320 - val_loss: 0.8972 - val_accuracy: 0.6981\n",
            "Epoch 13/100\n",
            "1250/1250 [==============================] - 102s 82ms/step - loss: 0.7526 - accuracy: 0.7407 - val_loss: 0.9220 - val_accuracy: 0.6847\n",
            "Epoch 14/100\n",
            "1250/1250 [==============================] - 96s 76ms/step - loss: 0.7238 - accuracy: 0.7497 - val_loss: 0.8761 - val_accuracy: 0.7039\n",
            "Epoch 15/100\n",
            "1250/1250 [==============================] - 91s 73ms/step - loss: 0.6965 - accuracy: 0.7637 - val_loss: 0.8871 - val_accuracy: 0.6986\n",
            "Epoch 16/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.6705 - accuracy: 0.7718 - val_loss: 0.8460 - val_accuracy: 0.7186\n",
            "Epoch 17/100\n",
            "1250/1250 [==============================] - 74s 59ms/step - loss: 0.6461 - accuracy: 0.7801 - val_loss: 0.9013 - val_accuracy: 0.6939\n",
            "Epoch 18/100\n",
            "1250/1250 [==============================] - 85s 68ms/step - loss: 0.6193 - accuracy: 0.7901 - val_loss: 0.8478 - val_accuracy: 0.7172\n",
            "Epoch 19/100\n",
            "1250/1250 [==============================] - 73s 59ms/step - loss: 0.5945 - accuracy: 0.7977 - val_loss: 0.8423 - val_accuracy: 0.7213\n",
            "Epoch 20/100\n",
            "1250/1250 [==============================] - 72s 58ms/step - loss: 0.5702 - accuracy: 0.8081 - val_loss: 0.8434 - val_accuracy: 0.7171\n",
            "Epoch 21/100\n",
            "1250/1250 [==============================] - 85s 68ms/step - loss: 0.5454 - accuracy: 0.8190 - val_loss: 0.8649 - val_accuracy: 0.7181\n",
            "Epoch 22/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.5244 - accuracy: 0.8239 - val_loss: 0.8513 - val_accuracy: 0.7171\n",
            "Epoch 23/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.5008 - accuracy: 0.8330 - val_loss: 0.8378 - val_accuracy: 0.7217\n",
            "Epoch 24/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.4767 - accuracy: 0.8397 - val_loss: 0.8752 - val_accuracy: 0.7169\n",
            "Epoch 25/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.4555 - accuracy: 0.8489 - val_loss: 0.8572 - val_accuracy: 0.7218\n",
            "Epoch 26/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.4330 - accuracy: 0.8566 - val_loss: 0.8559 - val_accuracy: 0.7229\n",
            "Epoch 27/100\n",
            "1250/1250 [==============================] - 78s 63ms/step - loss: 0.4121 - accuracy: 0.8649 - val_loss: 0.8844 - val_accuracy: 0.7228\n",
            "Epoch 28/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.3903 - accuracy: 0.8734 - val_loss: 0.8570 - val_accuracy: 0.7290\n",
            "Epoch 29/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.3706 - accuracy: 0.8806 - val_loss: 0.9261 - val_accuracy: 0.7153\n",
            "Epoch 30/100\n",
            "1250/1250 [==============================] - 78s 63ms/step - loss: 0.3493 - accuracy: 0.8875 - val_loss: 0.8766 - val_accuracy: 0.7303\n",
            "Epoch 31/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.3290 - accuracy: 0.8947 - val_loss: 0.9422 - val_accuracy: 0.7183\n",
            "Epoch 32/100\n",
            "1250/1250 [==============================] - 77s 62ms/step - loss: 0.3093 - accuracy: 0.9019 - val_loss: 0.9242 - val_accuracy: 0.7204\n",
            "Epoch 33/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.2912 - accuracy: 0.9087 - val_loss: 0.9557 - val_accuracy: 0.7115\n",
            "Epoch 34/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.2720 - accuracy: 0.9161 - val_loss: 0.9527 - val_accuracy: 0.7216\n",
            "Epoch 35/100\n",
            "1250/1250 [==============================] - 74s 59ms/step - loss: 0.2546 - accuracy: 0.9218 - val_loss: 0.9834 - val_accuracy: 0.7236\n",
            "Epoch 36/100\n",
            "1250/1250 [==============================] - 68s 55ms/step - loss: 0.2387 - accuracy: 0.9290 - val_loss: 0.9799 - val_accuracy: 0.7197\n",
            "Epoch 37/100\n",
            "1250/1250 [==============================] - 70s 56ms/step - loss: 0.2222 - accuracy: 0.9337 - val_loss: 0.9880 - val_accuracy: 0.7276\n",
            "Epoch 38/100\n",
            "1250/1250 [==============================] - 76s 61ms/step - loss: 0.2061 - accuracy: 0.9385 - val_loss: 1.0363 - val_accuracy: 0.7192\n",
            "Epoch 39/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.1900 - accuracy: 0.9439 - val_loss: 1.0940 - val_accuracy: 0.7095\n",
            "Epoch 40/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.1754 - accuracy: 0.9495 - val_loss: 1.0607 - val_accuracy: 0.7200\n",
            "Epoch 41/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.1626 - accuracy: 0.9531 - val_loss: 1.0784 - val_accuracy: 0.7252\n",
            "Epoch 42/100\n",
            "1250/1250 [==============================] - 84s 68ms/step - loss: 0.1477 - accuracy: 0.9596 - val_loss: 1.0978 - val_accuracy: 0.7255\n",
            "Epoch 43/100\n",
            "1250/1250 [==============================] - 82s 65ms/step - loss: 0.1349 - accuracy: 0.9632 - val_loss: 1.1380 - val_accuracy: 0.7217\n",
            "Epoch 44/100\n",
            "1250/1250 [==============================] - 83s 67ms/step - loss: 0.1236 - accuracy: 0.9669 - val_loss: 1.1822 - val_accuracy: 0.7165\n",
            "Epoch 45/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.1137 - accuracy: 0.9708 - val_loss: 1.1920 - val_accuracy: 0.7231\n",
            "Epoch 46/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.1041 - accuracy: 0.9733 - val_loss: 1.2910 - val_accuracy: 0.7042\n",
            "Epoch 47/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0937 - accuracy: 0.9766 - val_loss: 1.2523 - val_accuracy: 0.7212\n",
            "Epoch 48/100\n",
            "1250/1250 [==============================] - 83s 67ms/step - loss: 0.0846 - accuracy: 0.9805 - val_loss: 1.3004 - val_accuracy: 0.7202\n",
            "Epoch 49/100\n",
            "1250/1250 [==============================] - 79s 63ms/step - loss: 0.0762 - accuracy: 0.9822 - val_loss: 1.3853 - val_accuracy: 0.7057\n",
            "Epoch 50/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.0678 - accuracy: 0.9843 - val_loss: 1.3917 - val_accuracy: 0.7116\n",
            "Epoch 51/100\n",
            "1250/1250 [==============================] - 91s 73ms/step - loss: 0.0615 - accuracy: 0.9862 - val_loss: 1.4175 - val_accuracy: 0.7138\n",
            "Epoch 52/100\n",
            "1250/1250 [==============================] - 106s 84ms/step - loss: 0.0558 - accuracy: 0.9876 - val_loss: 1.4453 - val_accuracy: 0.7134\n",
            "Epoch 53/100\n",
            "1250/1250 [==============================] - 84s 67ms/step - loss: 0.0500 - accuracy: 0.9900 - val_loss: 1.4448 - val_accuracy: 0.7182\n",
            "Epoch 54/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0446 - accuracy: 0.9904 - val_loss: 1.4940 - val_accuracy: 0.7191\n",
            "Epoch 55/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0398 - accuracy: 0.9928 - val_loss: 1.5778 - val_accuracy: 0.7164\n",
            "Epoch 56/100\n",
            "1250/1250 [==============================] - 83s 67ms/step - loss: 0.0358 - accuracy: 0.9932 - val_loss: 1.5651 - val_accuracy: 0.7176\n",
            "Epoch 57/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0332 - accuracy: 0.9934 - val_loss: 1.5986 - val_accuracy: 0.7153\n",
            "Epoch 58/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0285 - accuracy: 0.9953 - val_loss: 1.6402 - val_accuracy: 0.7190\n",
            "Epoch 59/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0254 - accuracy: 0.9956 - val_loss: 1.7032 - val_accuracy: 0.7140\n",
            "Epoch 60/100\n",
            "1250/1250 [==============================] - 81s 64ms/step - loss: 0.0236 - accuracy: 0.9958 - val_loss: 1.7932 - val_accuracy: 0.7102\n",
            "Epoch 61/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 1.7591 - val_accuracy: 0.7148\n",
            "Epoch 62/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0196 - accuracy: 0.9966 - val_loss: 1.7961 - val_accuracy: 0.7175\n",
            "Epoch 63/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 1.8224 - val_accuracy: 0.7164\n",
            "Epoch 64/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 1.8744 - val_accuracy: 0.7138\n",
            "Epoch 65/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0140 - accuracy: 0.9979 - val_loss: 1.9013 - val_accuracy: 0.7186\n",
            "Epoch 66/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0128 - accuracy: 0.9981 - val_loss: 1.9252 - val_accuracy: 0.7156\n",
            "Epoch 67/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0120 - accuracy: 0.9977 - val_loss: 1.9720 - val_accuracy: 0.7190\n",
            "Epoch 68/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0115 - accuracy: 0.9979 - val_loss: 2.0270 - val_accuracy: 0.7153\n",
            "Epoch 69/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0103 - accuracy: 0.9983 - val_loss: 2.0199 - val_accuracy: 0.7152\n",
            "Epoch 70/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 2.0903 - val_accuracy: 0.7152\n",
            "Epoch 71/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 2.1045 - val_accuracy: 0.7153\n",
            "Epoch 72/100\n",
            "1250/1250 [==============================] - 82s 65ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 2.1261 - val_accuracy: 0.7192\n",
            "Epoch 73/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0070 - accuracy: 0.9990 - val_loss: 2.1797 - val_accuracy: 0.7109\n",
            "Epoch 74/100\n",
            "1250/1250 [==============================] - 82s 65ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 2.2012 - val_accuracy: 0.7186\n",
            "Epoch 75/100\n",
            "1250/1250 [==============================] - 81s 65ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 2.3252 - val_accuracy: 0.7083\n",
            "Epoch 76/100\n",
            "1250/1250 [==============================] - 82s 65ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 2.3104 - val_accuracy: 0.7115\n",
            "Epoch 77/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 2.3153 - val_accuracy: 0.7151\n",
            "Epoch 78/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 2.3468 - val_accuracy: 0.7175\n",
            "Epoch 79/100\n",
            "1250/1250 [==============================] - 82s 66ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 2.3376 - val_accuracy: 0.7173\n",
            "Epoch 80/100\n",
            "1250/1250 [==============================] - 82s 65ms/step - loss: 0.0048 - accuracy: 0.9989 - val_loss: 2.3897 - val_accuracy: 0.7162\n",
            "Epoch 81/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0047 - accuracy: 0.9989 - val_loss: 2.4255 - val_accuracy: 0.7148\n",
            "Epoch 82/100\n",
            "1250/1250 [==============================] - 83s 66ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 2.4379 - val_accuracy: 0.7147\n",
            "Epoch 83/100\n",
            "1250/1250 [==============================] - 80s 64ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 2.4647 - val_accuracy: 0.7163\n",
            "Epoch 84/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0042 - accuracy: 0.9990 - val_loss: 2.4822 - val_accuracy: 0.7150\n",
            "Epoch 85/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 2.5501 - val_accuracy: 0.7157\n",
            "Epoch 86/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 2.5822 - val_accuracy: 0.7159\n",
            "Epoch 87/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 2.5921 - val_accuracy: 0.7175\n",
            "Epoch 88/100\n",
            "1250/1250 [==============================] - 76s 61ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 2.8708 - val_accuracy: 0.6940\n",
            "Epoch 89/100\n",
            "1250/1250 [==============================] - 77s 61ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 2.6611 - val_accuracy: 0.7123\n",
            "Epoch 90/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 2.6846 - val_accuracy: 0.7140\n",
            "Epoch 91/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 2.7277 - val_accuracy: 0.7172\n",
            "Epoch 92/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 2.7257 - val_accuracy: 0.7138\n",
            "Epoch 93/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.7659 - val_accuracy: 0.7166\n",
            "Epoch 94/100\n",
            "1250/1250 [==============================] - 78s 62ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 2.7688 - val_accuracy: 0.7170\n",
            "Epoch 95/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.8066 - val_accuracy: 0.7175\n",
            "Epoch 96/100\n",
            "1250/1250 [==============================] - 76s 61ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 2.8129 - val_accuracy: 0.7187\n",
            "Epoch 97/100\n",
            "1250/1250 [==============================] - 76s 60ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 2.9173 - val_accuracy: 0.7149\n",
            "Epoch 98/100\n",
            "1250/1250 [==============================] - 76s 61ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 2.8728 - val_accuracy: 0.7190\n",
            "Epoch 99/100\n",
            "1250/1250 [==============================] - 75s 60ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 2.9136 - val_accuracy: 0.7154\n",
            "Epoch 100/100\n",
            "1250/1250 [==============================] - 76s 60ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 2.9624 - val_accuracy: 0.7151\n",
            "Test loss: 3.0557003021240234 / Test accuracy: 0.7111999988555908\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./saved_model\\assets\n"
          ]
        }
      ],
      "source": [
        "# Fit data to model\n",
        "history_=model.fit(x_train, y_train,\n",
        "          batch_size=32,\n",
        "          epochs=100,\n",
        "          verbose=1,\n",
        "          validation_split=.2)\n",
        "\n",
        "# Generate generalization metrics\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')\n",
        "\n",
        "# # Save the model\n",
        "filepath = './saved_model'\n",
        "save_model(model, filepath)\n",
        "\n",
        "# Load the model\n",
        "model = load_model(filepath, compile = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "3b53d3ebc9ab588da17f6fff91cb07c6116aee8ae1f5ab3dcaac78344e70010d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
